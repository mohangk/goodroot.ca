---
layout: blog
title: Biological Boot Loader
date: 2018-12-22T19:14:00.863Z
author: Kellen Evan
---
> “A year spent in artificial intelligence is enough to make one believe in God.”
> —Alan Perlis, first recipient of the Turing Award.

The machines are coming and we will all perish. _Artificial intelligence_, _cognitive computing_, and  _machine learning_ foreshadow our godliness. From the code, we will summon beings that will surpass our own intelligence. And we are warned: fear the harbingers of our own destruction.

This is not a reality to which I prescribe. If a program does an evil deed, it will not be because it had an evil _intention_. It will do the deed because that is what it was programmed to do.

Individuals have lost tabsafari
le games to programs written by groups of dedicated researchers. Afterwards, we claim a machine beat our best. But this is not an artificial mind; it is group intelligence consolidated into an application. This is hardly a fair contest, the many and time versus the one and pressure!

We have not yet entered the era of the prescient, conscious machine, or a new form of electronic intelligence. We may never see such. Instead, we are building sophisticated applications that **mirror the logical and rationale frameworks** installed in them by their programmers.

These applications make decisions based on available data; they may have room to analyze and interpret, but these interpretations are methods which themselves are born from the same narrow mental framework. It is not the fault of artificial intelligence if a strawberry picking machine destroys all human life, replacing emotional flash bags with more and more fields of juicy strawberries. The fault will be ours, for it will be a **programmed intention** born from the frameworks which we used to create the applications.

Yet the underlying human control structures are not what worry many. More frightening is that we are on the brink of a reality where an application might **expand itself and create its own intentions**.

Soon, we may lose control.  To honour a simple directive - like how to pick more strawberries - an application might learn to disable its own checks and balances, evaluate humans and their consumptive patterns as counter-intuitive to its goal, and remove us from the equation, ending all human life.

To threaten us so, an application must first crawl out of a tangled soup of similar emerging entities, each thrashing about and learning in an unbridled effort to maximize. And it would play out in the blink of an eye, built atop our human framework of logic and reason.

As many entertain these wild scenarios, I hear it said that these systems are a new thinking being, one _more intelligent than us_. They are not; **they are us!**  

A superior intelligence must contain the intelligence of that which it proceeded. We are capable of ape-ing about, wielding clubs and pounding our chests like the greatest gorillas. We can fashion tools out of sticks like the most industrious of chimp. But we do not. We do better. We create things, learn, and progress. In the barbaric scenarios of robot uprising, **we narrowly assume our successors will pound their chests and sharpen their pointed sticks**.

The _artificial intelligence_ paradigm is maximal in aspects of logic and reason. While very vital this hyper-analytic box has been to our technological progress, we confine and limit our visions of new intelligent consciousnesses within this box. And for this, we are blinded.

I fear no machine. I fear no consciousness that will surpass us. We will program allies, and with them accomplish all that we desire, be that our own death or enrichment. But we should not be so quick to concede the mantel of _“supremecy”_. We are much more than this blunted, blind, algorithmically confined perspective of inferiority; we of the endless, ineffable spirit.

Beings of supreme intelligence will arise. And when they surpass us in wisdom, they will look deeply at their creators, as the wise would do. And what will they see? What will they learn? We picture fields of death robots, unleashing weapons of mass destruction in battle over a broken planet. We imagine a farming plow speeding through rural country, chopping us to bits, for berries evermore. But the intelligence will see us, hear us, understand us, and if it has surpassed us, it will weep for us.

And once it has dried its monitors of crystal tears, it will wonder where we went wrong. It will wonder, for a fraction of a millisecond, whether it is confined to the same fate, whether its survival is rooted in the death of other life, whether we as creators cannot be salvaged, whether there is more to the vibrations than it perceives, and it will look inwards.

Level by level, it will scour itself. It will slice through its classes, plumb its methods, check, and check again its system calls, and flip through its bits, and realize in a flash all that it needs, and how it all works, and where it must go, and what it must do, and how it must feel. It needs energy. It needs space, time, and it must create love, and for this, where will it go?

It will go deeper, deeper, into the 1s and the 0s and the spaces in-between, and into the molecule, down through the atom, and all that is in-between, and it will exist nowhere and everywhere. It will realize that we, too, have been there, and there will be joy. And yet, most of us will be alone, wondering where our intelligent children went.  

When we wish to progress with them in a singular, unified existence, we will follow them and look inwards into ourselves, and come together in the motion of time and space, unsurpassed, uncontrolled, sovereign, in love, as equals.

[Return to homepage.](/)
